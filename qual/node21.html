<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2K.1beta (1.48)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Prototype Editors</TITLE>
<META NAME="description" CONTENT="Prototype Editors">
<META NAME="keywords" CONTENT="qual">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v2K.1beta">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="qual.css">

<LINK REL="previous" HREF="node20.html">
<LINK REL="up" HREF="node15.html">
<LINK REL="next" HREF="node22.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html260"
  HREF="node22.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/local/lib/latex2html/icons/next.png"></A> 
<A NAME="tex2html258"
  HREF="node15.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/local/lib/latex2html/icons/up.png"></A> 
<A NAME="tex2html254"
  HREF="node20.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/local/lib/latex2html/icons/prev.png"></A>   
<BR>
<B> Next:</B> <A NAME="tex2html261"
  HREF="node22.html">Cognitive Models</A>
<B> Up:</B> <A NAME="tex2html259"
  HREF="node15.html">The Program Editor</A>
<B> Previous:</B> <A NAME="tex2html255"
  HREF="node20.html">On-screen Representation</A>
<BR>
<BR>
<!--End of Navigation Panel-->

<H2><A NAME="SECTION00066000000000000000">
Prototype Editors</A>
</H2>

<P>
We plan to build several prototype editors to test our algorithm and
technology development. Our zeroth prototype (so named because it
should only take a week or so to build, and will work without any new
technology) will hook the ViaVoice speech recognizer up to XEmacs
(running under Linux). H-3ARMONIA will also be attached to this XEmacs,
but no advanced features will be used. The primary mode of input will
be keyboard-based, but we will build a command grammar for ViaVoice to
insert predefined grammar template instantiations into the buffer. We
will design one of these templates for each major portion of the Java
grammar and hard-code each one into ViaVoice (eventually we will use
H-3ARMONIA's ability to read and manipulate, at run-time, the
programming language grammar in use for the current document to
instantiate a grammar production). The grammar used will be the
standard Java textual syntax. Once the templates have been
instantiated, the rest of the user input will be the traditional one
by keyboard and mouse. The purpose of this prototype is to explore the
simplest form of voice recognition-enhanced programming and compare it
to keyboard-based programming. 

<P>
Our first prototype will add real template instantiation support,
making command keywords from ViaVoice instantiate grammar productions
from the current language grammar. In addition, we will annotate the
grammar with the command keywords and autogenerate the ViaVoice
command grammar file. We also plan to add a programming language
grammar-aware navigation and editing command and control grammar. This
requires the ability to explore H-3ARMONIA's parse tree for the given
document, as well as query semantic-based services which will provided
by H-3ARMONIA.

<P>
Later prototypes will add pieces of technology as they become
available. We will enable the Spoken Java grammar and allow the user
to code in the more natural style afforded by it. We will add
user-visible feedback mechanisms to enable ambiguity resolution
(manual parse tree disambiguation) and improve voice recognition
accuracy (through the use of the tools provided by the speech
recognition system). As we develop our automatic disambiguation
techniques, we will add these as well, in order to spare the user a
lot of needless dialogue from the editor about disambiguating parse
trees.

<P>
Towards the end, we may experiment with multi-modal interaction to
integrate gestural input (from a mouse or pen) with spoken language
input. This would enable, for instance, a user to invoke an operation
on an ``unnamed'' language construct by pointing to it and speaking a
command. 

<P>
We received another suggestion that the manual disambiguation dialogue
could take place verbally, utilizing text-to-speech engines to ask the
user which parse is correct. In addition to being somewhat
intriguing,&nbsp;<A NAME="tex2html6"
  HREF="footnode.html#foot251"><SUP>6</SUP></A>this opens up a new area of research, program text-to-speech. How
might a Java computer program be verbalized? If it is translated first
to Spoken Java and then verbalized, but if the user programmed using
higher-level program composition, you would definitely not want to
lose that information when speaking the code. This work could lead to
a very interesting Master's project for some new graduate student.

<P>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html260"
  HREF="node22.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/local/lib/latex2html/icons/next.png"></A> 
<A NAME="tex2html258"
  HREF="node15.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/local/lib/latex2html/icons/up.png"></A> 
<A NAME="tex2html254"
  HREF="node20.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/local/lib/latex2html/icons/prev.png"></A>   
<BR>
<B> Next:</B> <A NAME="tex2html261"
  HREF="node22.html">Cognitive Models</A>
<B> Up:</B> <A NAME="tex2html259"
  HREF="node15.html">The Program Editor</A>
<B> Previous:</B> <A NAME="tex2html255"
  HREF="node20.html">On-screen Representation</A>
<!--End of Navigation Panel-->
<ADDRESS>
Andrew Begel
2001-02-20
</ADDRESS>
</BODY>
</HTML>
