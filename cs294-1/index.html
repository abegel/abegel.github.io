<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"><html>	<head>		<meta http-equiv="content-type" content="text/html;charset=ISO-8859-1">		<meta name="generator" content="Adobe GoLive 6">		<title>CS294-1 Class Project</title>	</head>	<body bgcolor="#ffffff">		<h1>Voice-Over Comments while Programming</h1>		<h3>Introduction</h3>		<p>It has long been the case that anyone grading a programming assignment laments that they don't understand how a student could have possibly come up with the answers that they did. Students don't comment their code enough, and the code itself is usually written in a language or style that is particularly obtuse. Plus, the turned in copy represents only a tiny fraction of the code that the student actually typed in while trying to make their project. </p>		<p>Wouldn't it be nice, if you could follow a student's thought process along from beginning to end, and see not just the end product of their efforts, but all intermediate stages in between. Even better, if you could not only watch their code develop, but you could also hear what they were thinking when they wrote it? That would give a teacher/grader much more information to work with in order to understand <i>how</i> a student developed their code, and more easily identify where they went wrong (and, where they had a great flash of insight!). </p>		<p>In this project, we will add voice-over comments to Harmonia-Mode, a programming language editor built on top of <a href="http://www.xemacs.org">XEmacs</a> and the <a href="http://www.cs.berkeley.edu/%7eharmonia">Harmonia</a> project. Harmonia-Mode, in addition to providing a whole host of syntactic and semantic analysis services to the programmer, also keeps a log of all edits made to a program over the program's lifetime. For this project, we will create the ability to record the voice of the user (with speech-to-text translation to make skimming easier for the reader) and embed it into the program document at a proper location, and enable a reader to turn a history dial from beginning to end to see every state of the program. Perhaps we'll even create a movie feature so a reader can watch a program unfold without intervention. </p>		<h3>Related Work</h3>		<p>Working on it....</p>		<h3>Implementation</h3>		<p>There are a few design questions to answer before we delve into the implementation. </p>		<ol>			<li>How should voice comments be represented in the parse tree? 			<ol>				<li type="a">If they're attributes on existing nodes, they will go away when the node is recreated, either through lexing or parsing. Also, how do you know which node to associate with a comment?				<li type="a">We could make them into their own type of comment node; this involves enhancing Harmonia to support multiple lexers, some that process the programming language text, and others that process sound streams (and optional speech-to-text translation). One flaw with this plan is that a voice comment is just as low level as a normal textual comment; there's no higher-level association with any program structure.			</ol>			<li>To what node are comments associated? If a user speaks a comment, where does it go in the tree?			<ol>				<li type="a">It could go where the cursor is. However, if the user moves the cursor while speaking, do we insert the comment as a contiguous block at the starting location, or do we split it up into chunks, each one going in between the next pair of text tokens?				<li type="a">We could speech-to-text convert the comment and try to figure out what the person is talking about, and insert the comment in the place being referred to. <b>Too hard!</b>				<li type="a">If the comment is inserted in a particular place in the tree as a leaf node, could we create comment links from each of its nonterminal parents in the tree? That way, one could associate a voice comment with a higher-level structure than just the previous token. There might not be a unique nonterminal to associate it with. Perhaps allow the user to choose which one(s) to keep it attached to?				<li type="a">Make the spoken utterance modal, and when it's finished, ask the user to click on the location in the program where they want the comment to go. 			</ol>		</ol>		<p>This project involves creating three main enhancements to Harmonia. </p>		<ol>			<li>Enhance Harmonia's incremental lexer to support lexemes that aren't textual.			<li>Enhance Harmonia-Mode to display and edit non-textual AST leaf nodes. Also allow a user to play back a voice comment and optionally speech-to-text it and insert the text next to the voice comment as an alternate visualization.			<li>Enhance Harmonia-Mode to &quot;play back&quot; the history of what the user did from beginning to end playing the sound clips at the correct time. Harmonia has to remember the time stamps of when each edit occurred.		</ol>		<h3>Project Milestones</h3>
		<ol>			<li>Make the changes necessary to the incremental lexer to get voice comments to be insertable into the parse tree, and stay there.			<li>Enhance Harmonia-Mode to display voice comments as a glyph, and define its editing model.			<li>Be able to save voice comments in the write-log, and load them back in. Voice clips will probably be need to be saved as base64'd gzip'd entries in the hlog.			<li>Add timestamps to Harmonia-Mode's log format.			<li>Testing.			<li>Pilot study - ask one or two students to use application to code a CS61B assignment in Java.			<li>Redesign the UI to make it more intuitive and easy to use, based on the user study. 			<li>Bigger study? (CPHS approval).
			<li>Write report and poster.
		</ol>
		<hr>
		<h3>Project Progress Report (April 9, 2002)</h3>
		<p>As of today, I've completed a number of implementation tasks. </p>
		<ol>
			<li>I created a LexerChoiceMixin class to record per-token-type information to support using a different lexer for voice comments. 
			<li>I created a VoiceComment token type and registered it as a comment in my java.ldl file. 
			<li>I created a VoiceCommentLexer subclass of AbstractBatchLexer which will properly return the VoiceComment it finds in the text of the document. 
			<li>I modified the incremental lexer to understand the lexing semantics of the VoiceComment. A VoiceComment (or anytime you switch lexers while processing a list of tokens)  represents an EOF to any token before it and a BOS for any token afterwards. This implies that the lookahead for the token before the VoiceComment must be 0, and the lookback for any tokens after the VoiceComment can go back past the VoiceComment.
			<li>Added a prototype function to harmonia-mode in XEmacs to insert a generic VoiceComment token into the AST whose text reads &quot;This is a voice comment&quot;. Harmonia-mode can display these nodes as normal text, but does not support the correct display/edit model yet. 
		</ol>
		<p>The next two steps are to prototype and implement the proper display and editing model for Voice Comments in harmonia-mode, and then hook up the speech recognizer to record dictation and emit voice comments as a result. </p>
		<p></p>
		<p></p>
	</body></html>